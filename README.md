# Jess Lee T1A1-Workbook 

## Question 1

Markup Languages (ML) are systems that utilise sets of annotations such as tags and elements in a text document making it easier for computers to interpret and manipulate the text. These rules define and govern how elements such as text or images are presented digitally. There are many different types of Markup Languages, however some of the most common for web development include HTML (Hypertext Markup Language), SGML (Standard Generalised Markup Language) and XML (Extensible Markup Language) (Ben Sadok, 2021).

A major benefit of Markup Languages is improving Search Engine Optimisation (SEO) quality. HTML utilises semantic tags which define sections on a webpage which allows browsers, search engines and other developers to read and understand the flow of content easier (Ben Sadok, 2021). There are many different semantic tags that can be used and are generally divided for either Structure ie. `<header>, <main>, <section>` etc. or Text elements ie. `<h1> to <h6>, <p>` etc. By using semantic language, it adds an additional layer of information which makes the information more comprehensible and allows search engines to pinpoint crucial information on the webpage. This effectively assists in increasing the chances of a websites content to rank higher on the results page against the relevant keywords of the search. By implementing responsive design principles, it ensures websites are optimised depending on the device they are viewed on. This not only improves user experience by changing how websites are viewed on different sized screens, but also boosts SEO as Google now priortises results that are mobile-friendly. 

Additionally, Markup Languages enhance accessibility for users with disabilities making it easier to interact with websites, and simply more user-friendly for everyone. It enables assistive technologies such as screen readers, to interpret and output the information in ways the user requires to access it. An example of this would be using Alt Text for images with meaningful descriptions which lets screenreaders comprehend the context of an image and greatly increases the browsing experience for visually impaired users. By ensuring a website is highly assessible, it allows websites to reach wider audience which can be overlooked often. The World Wide Web Consortium (W3C) have created Web Content Accessibility Guidelines (WCAG) which makes it easier for developers and designers to follow and produce an accessible website.

## Question 2

### Packets

A packet is a small unit or portion of data that is sent over a computer network. This method of splitting and sending data is known as Packet Switching. Each packet contains part of a complete message that hold important address information of the sending computer and its intended recipient, where the packets are then reordered into a single file at their destination. Packet loss occurs when one or more packets fail to reach the intended destination, resulting in information loss.

A network that facilitates packet is known as a Packet-Switching network. The worlds first Packet-Switching Network was developed in 1969 by Advanced Research Projects Agency of the U.S. Department of Defense (ARPA) named ARPANET. This invention provided the foundation in which the internet still operates today. As ARPANET evolved, it required governance which supported the invention of a new method named Transmission-Control Protocol (TCP/IP) (ScienceMediaMuseum.org, 2020).

### IP Addresses (IPv4 and IPv6)

An Internet Protocol (IP) Address is a unique indentification number that is assigned to all devices connected to the internet. It is used for computers to efficiently communicate with each other over the internet or local networks to share information to specific locations. An IP Address has two parts, one of which identifies the host and the other the network is belongs to.

There are two core versions or standards of Internet Protocol, which are IP Version 4 and Version 6. IPv4 was first launched in 1981 by the Internet Engineering Task Force (IETF) and later adopted by ARPANET in 1983. It still routes a majority of the internet traffic today and is a popular protocol for communication over the internet, however it's greatest limitation is that it can host just under 4.3 Billion possible IPv4 addresses due to 32-bit address format. This limitation is essentially solved by IPv6 as it uses a 128-bit address format which allows approximately 340 undecillion (2^128) possible IP addresses. Other improvements over IPv4 include autoconfiguration, routing and security upgrades. However, despite these improvements, the migration from IPv4 to v6 is expensive and complex, hence why most of the internet stills runs on IPv4 (geeksforgeeks.org, 2023). 

### Routers and Routing

Routing is the process of selecting the path in which the packets of information/data are transmitted across one or multiple networks (Rouse, 2023). These decisions are facilitated by devices known as routers. A router guides packets between two or more packet-switched networks. Its primary functions are to manage traffic between the networks and allowing multiple devices to utilise the same Internet Connection. Most routers today allow devices to connect to the internet wirelessly (Wifi).

### Domains and DNS

Domain Name System (DNS) is a protocol for how computers relay data over the internet. It aids in converting user-friendly names which are easy to understand into an IP address which computers then use to identify on the network (Brain et al., 2024). It was invented in 1983 by Paul Mockapetris and has been pivotal in shaping the internet as we know it today. DNS makes it easier for us as users to navigate websites with easy to remember names and eliminates the need for memorising individual IP addresses (Villanueva, 2021). Without a DNS translating the domain names to correct IP address, it would make it much more difficult to access the websites we want, especially if IP addresses were to change for whichever reason, DNS still allows us to view the page with the same domain name. 

## Question 3

### TCP

Transmission Control Protocol (TCP) is the internet protocol establishes a connection between computers, allowing them to communicate between each other by transferring data over long distances. As the internet is a packet-switched network, the data is broken down into small packets which are sent individually through different routes (facilitated by routers) and then reassembled at the destination (BasuMallick, 2022). Since it's inception in the 1970's-80's when the internet was being built, it has been a cornerstone in the development of communication over the internet. It provides a reliable method to transmit data over the internet, ensuring data is delivered accurately in its correct order (Kurose & Ross, 2021). Its design has effectively enabled it to scale with the current growth of the internet and served as a foundation for the advancing of many internet technologies (Severance, 2015). This has been accomplished by standardising the information delivery so all hosted applications on the internet are interoperable (BasuMallick, 2022).

### HTTP and HTTPS

### Web Browsers

## Question 4

Compilers (eg. C, C++) and Interpreters (eg. JS) are programs that take high-level language or source code, that we humans understand, and converts it into machine language; each with their own advantages and disadvantages. The main difference between the two is that, a compiler will read the entire code that is saved to a file before it is executed; whereas interpreters read source code line by line while the program is running (Ben Sassi, 2023). Compiled code generally takes longer to analyse than Interpreted as it goes through the entire code, but consequently the program will run faster than interpreted code being analysed line by line while the program is being executed. 

Compilers will display all errors after it's been compiled and interpreters will display the errors of each line individually which makes it simpler to debug. This in turn means that compilers generally consume more memory than interpreters. Another reason Compiled code is faster is due to it being optimised to the device or platform that is is run on, although this can also be a disadvantage as it means the programs may not be cross-platform compatible. Once code has been compiled, the executable file can be launched without needing any of the source code which provides some confidentiality. Interpreters always require the source code for processing but can be executed on any machine or device without compatibility issues (BasuMallick, 2023).

Both compilers and interpreters have unique applications and do not replace each other.



## Question 5

https://www.netguru.com/blog/python-pros-and-cons
https://serokell.io/blog/python-pros-and-cons - Python






## Question 6

needs for the website
appropritae techniques
professional tools - html, css
wireframes


## Question 7

I have only had one previous software engineering project, which was creating my Website Portfolio for Coder Academy. The scenario I will be reflecting upon specifically is when I was trying to create the landing page for My Blogs and the Blog Article layout page. For this self-reflection, I will be adopting Gibbs' Reflective Cycle 1988, which explored six stages of the experience: description, feelings, evaluation, analysis, conclusion and action plan. I believe this reflection model covers many bases and offers a solid framework for examining many aspects of the experience (University of Edinburgh, n.d.).

### Description

I explicitly remember the difficulty I had designing these two pages. After I had spent hours designing my header and footer and having everything the way I liked, I moved onto designing the main blogs page and the blog article page with placeholder text. I was attempting to utilise CSS Grid as I was previously working with CSS Flexbox and wanted to try to achieve the design I wanted with a different method. I wanted to create interactive and responsive tiles for each blog, centering them in the middle of the page. And for the individual blogs layout, I had decided to go with a generic article layout with the heading at the top, image on the right, and text wrapping around the image. Due to creating my wireframes and planning the layout beforehand, I knew exactly how I wanted those pages to look, the journey however, just wasn't what I expected. But I suppose that can be said about coding in general. I had allocated myself 3 hours after work to complete these pages, which I believed would be a generous amount of time after completing the Header and Footer over the last few days, so I had gained a bit of experience.

### Feeling

Going into the task, I had felt hopeful, as I managed to complete other areas of the website fairly smoothly, however for this specific task, I went through an entire array of emotions. The strongest and most frequent emotion I felt was frustration. Whenever I tried to place an element where I had imagined, it would throw everything else out of position. It was even worse when you felt like the code you had written would fix it, only to check liveshare and it look even worse than before. However all this frustration was followed with slight feelings of accomplishment after finally managing to do what you wanted. It was shortlived as you would start on a new element and the cycle would continue again. Reflecting on this now, I am proud of myself for persevering through that and not letting it overwhelm me completely. 

### Evaluation

The positives I can take away from this experience is that in the end, I did manage to complete it and have it working as planned. Designing the Blog Article page was much smoother than the main page, and I didn't encounter nearly as much trouble. Once I was able to get the image and heading how I wanted, it was very easy to have the text wrap around it. The most common thing that went wrong was having my main and footer not staying in position, or it affect the responsive design whilst I was trying to add the tiles. I did not manage to complete the task within the 3 hours I had initially given myself, however I did still finish it that night. The entire process for this task took just under 5 hours. A majority of that time spent on debugging or scrapping initial code and starting from scratch.

### Analysis

I believe the main reason things didn't go as well as they could have, was due to my code not being as optimised as it could have been. There were lines of code that affected the body in my index.css file that would affect the blog pages. It definitely helped planning the wireframes so I had clear direction in what I wanted to achieve, rather than just attempting different things and seeing what would work or look best as I went. A lot of the issues I faced was also due to lack of knowledge as I had zero coding experience beforehand, except for the classes, so stepping into this project was very daunting and took a lot of mental energy/fortitude. I spent a lot of time trying different things with CSS Grid, but I could not get it working the way I wanted, and switched to CSS Flexbox half way through. I decided this would be best as I had a stronger understanding of Flexbox and was able to debug more efficiently, rather than spending more time attempting to get Grid to work. Although I can't say it's by any means a strength, it was definitely comparatively stronger than my knowledge of grid. 

### Conclusion

There were many things I was able to take away from this experience. It helped me understand and become more comfortable being uncomfortable when things weren't going my way. This helped for the remainder of the project as I would inevitably be put into similar situations, which I would be able to navigate more efficiently. Although I didn't accomplish what I wanted using the method I originally planned, I still managed to achieve my end goal with a different path. I think this could have been a more positive experience had I researched a bit more, because for the specific design I was aiming for, it would have been been easier using Flexbox for the responsive design. I was unable to keep the grid the same when I was viewing it on different sized devices, and all the elements would wrap into ridiculous sizes. Wheras Flexbox kept the tiles the same and wrapped them exactly how I needed. As this was an indivudal project, I rarely asked questions in the support chat that Coder Academy offers. I felt that if I kept asking questions, I didn't want to annoy anyone or seem bothersome. I also partially felt some embarrassment as I thought what I wanted to achieve was an very simple thing to do, but I was having so much difficulty. I understand now having reflected on it, that I shouldn't let those things stop me from reaching out and asking for help when needed.

### Action Plan

If I were to work on a similar project and find myself in a similar position, the greatest take away for me would be to not hestitate and reach out to the support networks that I am offered. This would have saved me lots of time and effort as the educators could assess and tell me why it things weren't working as expected, rather than me having to go through all my different files of code to find the issue. I would research which would be the most efficient or optimised methods for what I would want to achieve, rather than attempting it blindly and forcing it to work, as most of the time there will be a better solution. I learned that planning is a crucial step and in future, I will spend more time in my planning phase. 


## Question 8

find events for networking

## Question 9

language learning technologies such as chatGPT

## Question 10

legal and ethical impacts 

## Question 11

soft skills
hard skills

## Question 12

roles/job positions in software development company

software architect
Full stack Developer
Product Manager
Dev Ops engineer

https://www.bairesdev.com/blog/software-development-roles/

## References
